{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BonaldSo/project_gan/blob/main/MyGANforMNISTdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "# Setting the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "batch_size = 100\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "#ToDo: Build the train data loader using the above batch_size varibale and shuffling the dataset.\n",
        "data_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "z-BU1m9IEXKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23d7c84-3bc0-4f00-9c48-51dde3ac6657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 79076304.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 58889496.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 21889057.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13568752.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CjKSZLfMNU2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, n_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        #The activation function for the two hidden layers is ReLU.\n",
        "        #The last layer's activation function is Tanh.\n",
        "        self.fc1 = nn.Linear(n_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 512)\n",
        "        self.fc3 = nn.Linear(512, 784)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #The function takes as input x and outputs the result of applying the generator on x.\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "uACYmlwwG2tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        #The activation functions for the two hidden layers are ReLU.\n",
        "        #The last layer's activation function is Sigmoid.\n",
        "        self.fc1 = nn.Linear(784, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # Making sure that the batch of images has the shape [batch_size,28*28] instead of [batch_size,1,28,28]\n",
        "        #The function takes as input x and outputs the result of applying the generator on x.\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "t5hdsi10JWJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_dim = 100\n",
        "generator = Generator(n_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "lr = 0.0002\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "#ToDo: define the two different Adam optimizers for generator and discriminator with learning rates of lr.\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "FyuaaCJLLCdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        real_images = images.to(device)\n",
        "\n",
        "        # Training discriminator\n",
        "        discriminator.zero_grad()\n",
        "        real_outputs = discriminator(real_images)\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        d_loss_real = criterion(real_outputs, real_labels)\n",
        "\n",
        "        #ToDo: Compute d_loss_fake\n",
        "        noise = torch.randn(batch_size, n_dim).to(device)\n",
        "        fimage = generator(noise)\n",
        "        foutput = discriminator(fimage.detach())\n",
        "        flabel = torch.zeros(batch_size, 1).to(device)\n",
        "        d_loss_fake = criterion(foutput, flabel)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Training generator\n",
        "        generator.zero_grad()\n",
        "\n",
        "        #ToDo: compute g_loss\n",
        "        myfoutput = discriminator(fimage)\n",
        "        g_loss = criterion(myfoutput, real_labels)\n",
        "\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        if (i+1) % 300 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], '\n",
        "                  f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "                  f'Generator Loss: {g_loss.item():.4f}')"
      ],
      "metadata": {
        "id": "RA8t-sCQZ8SG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08fd2f4-86ec-4e62-954b-6aef225ef52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Step [300/600], Discriminator Loss: 0.2267, Generator Loss: 4.0077\n",
            "Epoch [1/30], Step [600/600], Discriminator Loss: 0.8389, Generator Loss: 3.1468\n",
            "Epoch [2/30], Step [300/600], Discriminator Loss: 0.6616, Generator Loss: 2.4652\n",
            "Epoch [2/30], Step [600/600], Discriminator Loss: 1.5059, Generator Loss: 1.3780\n",
            "Epoch [3/30], Step [300/600], Discriminator Loss: 0.1482, Generator Loss: 2.9886\n",
            "Epoch [3/30], Step [600/600], Discriminator Loss: 0.5106, Generator Loss: 3.1385\n",
            "Epoch [4/30], Step [300/600], Discriminator Loss: 0.6059, Generator Loss: 3.0051\n",
            "Epoch [4/30], Step [600/600], Discriminator Loss: 0.3776, Generator Loss: 3.0690\n",
            "Epoch [5/30], Step [300/600], Discriminator Loss: 0.9257, Generator Loss: 1.5046\n",
            "Epoch [5/30], Step [600/600], Discriminator Loss: 0.2512, Generator Loss: 3.2882\n",
            "Epoch [6/30], Step [300/600], Discriminator Loss: 0.2331, Generator Loss: 3.2875\n",
            "Epoch [6/30], Step [600/600], Discriminator Loss: 0.2941, Generator Loss: 3.6637\n",
            "Epoch [7/30], Step [300/600], Discriminator Loss: 0.1434, Generator Loss: 5.8661\n",
            "Epoch [7/30], Step [600/600], Discriminator Loss: 0.1616, Generator Loss: 4.9586\n",
            "Epoch [8/30], Step [300/600], Discriminator Loss: 0.5235, Generator Loss: 2.8390\n",
            "Epoch [8/30], Step [600/600], Discriminator Loss: 0.6683, Generator Loss: 4.0952\n",
            "Epoch [9/30], Step [300/600], Discriminator Loss: 0.6894, Generator Loss: 2.4632\n",
            "Epoch [9/30], Step [600/600], Discriminator Loss: 0.4135, Generator Loss: 3.0907\n",
            "Epoch [10/30], Step [300/600], Discriminator Loss: 0.4262, Generator Loss: 3.1114\n",
            "Epoch [10/30], Step [600/600], Discriminator Loss: 0.9144, Generator Loss: 2.3193\n",
            "Epoch [11/30], Step [300/600], Discriminator Loss: 0.4049, Generator Loss: 3.5777\n",
            "Epoch [11/30], Step [600/600], Discriminator Loss: 0.3738, Generator Loss: 4.6146\n",
            "Epoch [12/30], Step [300/600], Discriminator Loss: 0.4220, Generator Loss: 2.9515\n",
            "Epoch [12/30], Step [600/600], Discriminator Loss: 0.6566, Generator Loss: 4.8370\n",
            "Epoch [13/30], Step [300/600], Discriminator Loss: 0.6082, Generator Loss: 2.8548\n",
            "Epoch [13/30], Step [600/600], Discriminator Loss: 0.3264, Generator Loss: 3.6654\n",
            "Epoch [14/30], Step [300/600], Discriminator Loss: 0.2207, Generator Loss: 4.6760\n",
            "Epoch [14/30], Step [600/600], Discriminator Loss: 0.2309, Generator Loss: 3.6856\n",
            "Epoch [15/30], Step [300/600], Discriminator Loss: 0.5557, Generator Loss: 3.6059\n",
            "Epoch [15/30], Step [600/600], Discriminator Loss: 0.2510, Generator Loss: 3.9360\n",
            "Epoch [16/30], Step [300/600], Discriminator Loss: 0.3641, Generator Loss: 3.6180\n",
            "Epoch [16/30], Step [600/600], Discriminator Loss: 0.5757, Generator Loss: 4.7579\n",
            "Epoch [17/30], Step [300/600], Discriminator Loss: 0.3854, Generator Loss: 3.1566\n",
            "Epoch [17/30], Step [600/600], Discriminator Loss: 0.3740, Generator Loss: 3.3276\n",
            "Epoch [18/30], Step [300/600], Discriminator Loss: 0.4024, Generator Loss: 4.6254\n",
            "Epoch [18/30], Step [600/600], Discriminator Loss: 0.3190, Generator Loss: 3.9107\n",
            "Epoch [19/30], Step [300/600], Discriminator Loss: 0.4861, Generator Loss: 3.0550\n",
            "Epoch [19/30], Step [600/600], Discriminator Loss: 0.4001, Generator Loss: 3.3756\n",
            "Epoch [20/30], Step [300/600], Discriminator Loss: 0.4014, Generator Loss: 4.0556\n",
            "Epoch [20/30], Step [600/600], Discriminator Loss: 0.3875, Generator Loss: 2.4643\n",
            "Epoch [21/30], Step [300/600], Discriminator Loss: 0.4612, Generator Loss: 2.5660\n",
            "Epoch [21/30], Step [600/600], Discriminator Loss: 0.5062, Generator Loss: 3.1170\n",
            "Epoch [22/30], Step [300/600], Discriminator Loss: 0.3764, Generator Loss: 2.6733\n",
            "Epoch [22/30], Step [600/600], Discriminator Loss: 0.5487, Generator Loss: 2.4234\n",
            "Epoch [23/30], Step [300/600], Discriminator Loss: 0.5400, Generator Loss: 3.6030\n",
            "Epoch [23/30], Step [600/600], Discriminator Loss: 0.4783, Generator Loss: 4.0151\n",
            "Epoch [24/30], Step [300/600], Discriminator Loss: 0.6264, Generator Loss: 2.6158\n",
            "Epoch [24/30], Step [600/600], Discriminator Loss: 0.6725, Generator Loss: 2.4976\n",
            "Epoch [25/30], Step [300/600], Discriminator Loss: 0.6377, Generator Loss: 2.6177\n",
            "Epoch [25/30], Step [600/600], Discriminator Loss: 0.5467, Generator Loss: 3.0467\n",
            "Epoch [26/30], Step [300/600], Discriminator Loss: 0.3857, Generator Loss: 3.0312\n",
            "Epoch [26/30], Step [600/600], Discriminator Loss: 0.7426, Generator Loss: 2.3485\n",
            "Epoch [27/30], Step [300/600], Discriminator Loss: 0.6361, Generator Loss: 3.1060\n",
            "Epoch [27/30], Step [600/600], Discriminator Loss: 0.4685, Generator Loss: 2.4465\n",
            "Epoch [28/30], Step [300/600], Discriminator Loss: 0.3711, Generator Loss: 4.2719\n",
            "Epoch [28/30], Step [600/600], Discriminator Loss: 0.4622, Generator Loss: 2.2405\n",
            "Epoch [29/30], Step [300/600], Discriminator Loss: 0.5672, Generator Loss: 3.0776\n",
            "Epoch [29/30], Step [600/600], Discriminator Loss: 0.5105, Generator Loss: 3.0752\n",
            "Epoch [30/30], Step [300/600], Discriminator Loss: 0.3697, Generator Loss: 3.0989\n",
            "Epoch [30/30], Step [600/600], Discriminator Loss: 0.6358, Generator Loss: 3.1377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "generator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(4, n_dim).to(device)\n",
        "    gimages = generator(noise).cpu().numpy()\n",
        "\n",
        "f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
        "for i, a in enumerate(ax.flatten()):\n",
        "    a.imshow(gimages[i].reshape(28, 28), cmap='gray')\n",
        "    a.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lvUJnaqSJCPM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "d13fc495-288d-4526-aafa-3c7ca2abe069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oKSG7J5gLocD"
      }
    }
  ]
}